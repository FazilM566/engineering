# HW06 – Report

## 1. Dataset

- Датасет: `S06-hw-dataset-02.csv`.
- Размер: (18000 строк, 39 столбцов).
- Целевая переменная: `target` (0 - 0.737389;1 - 0.262611).
- Признаки: числовые.

## 2. Protocol

- Разбиение: train/test (доли - 0.8/0.2, `random_state = 42`).
- Подбор: CV на train - `5` фолдов,оптимизируемая метрика: `ROC-AUC`.
- Метрики: `accuracy`, `F1`, `ROC-AUC` (т.к. бинарная классификация).

## 3. Models

- DummyClassifier (baseline).
- LogisticRegression, подбирал параметр регулизации `C`.
- DecisionTreeClassifier, подбирал `max_depth`,`min_samples_leaf` и `ccp_alpha`.
- RandomForestClassifier, подбирал `min_samples_leaf`.
- HistGradientBoosting, подбирал `max_depth` и `learning_rate`.
- StackingClassifier (с CV-логикой).

## 4. Results

- Финальные метрики у моделей на `test` выборке.   

baseline: 
`Accuracy`: 0.7375,
`F1`: 0.0,
`ROC-AUC`: 0.5

logistic_regression: 
`test_metrics`: 
`Accuracy`: 0.8088888888888889,
`F1`: 0.544973544973545,
`ROC-AUC`: 0.791725704720055

tree_reg: 
`Accuracy`: 0.8341666666666666,
`F1`: 0.6506729081334114,
`ROC-AUC`: 0.8427692583624786

RandomForest: 
`Accuracy`: 0.8927777777777778,
`F1`: 0.7623152709359606,
`ROC-AUC`: 0.9294122101655058

HistGradientBoosting: 
`Accuracy`: 0.9136111111111112,
`F1`: 0.8217765042979943,
`ROC-AUC`: 0.9294213772556523

Stacking: 
`Accuracy`: 0.9180555555555555,
`F1`: 0.8358375069560379,
`ROC-AUC`: 0.9294122101655058


- Лучшая модель по метрике `ROC-AUC` - HistGradientBoosting. Модели ансамблей оказались намного качественее других моделей, показатели метрики ROC-AUC у них
примерно равны, но все же градиентный бустинг превысел модели стэкинга и случайного леса.

## 5. Analysis
- Устойчивость (для лучшей модели):

`random_state` =  42
Accuracy : 0.9136111111111112
F1 : 0.8217765042979943
ROC-AUC  : 0.9294213772556523
 
`random_state` =  56
`Accuracy` : 0.9086111111111111
`F1` : 0.8116771608471666
`ROC-AUC`  : 0.9297637481441624
 
`random_state` =  64
`Accuracy` : 0.9
`F1` : 0.7906976744186046
`ROC-AUC`  : 0.928115664763499
 
`random_state` =  78
`Accuracy` : 0.91
`F1` : 0.8140068886337543
`ROC-AUC` : 0.9301005390647574
 
`random_state` =  89
`Accuracy` : 0.9033333333333333
`F1` : 0.7988439306358381
`ROC-AUC`  : 0.9290347651929572

метрики качества несильно менятся при различных значениях `random_state` (+- 0.1), что говорит об устойчивости модели.
- Ошибки (для лучшей модели):

confusion matrix:

`[2572   83]
[ 228  717]`

верные и ложные предсказания бинарных показателей распределены соответвенно разбросу целевой переменной в датасете.Поэтому ошибочно предсказанная `1` встречаечься чаще ошибочно предсказанного `0` (относительно верно предсказанных значений).
- Интерпретация для лучшей модели:
permutation importance:
1. f16
2. f01
3. f07
4. f08
5. f30
6. f23
7. f19
8. f15
9. f18
10. f13
выводы: f16 оказался самым важным признаком,его влияние на прогноз модели наивысшее.

## 6. Conclusion

Деревья позволяют решать задачи классификации с нелинейными признаками. Ансамбли же действительно создают более качественные и точные модели,за счет того, что работают с более чем одной моделью. Честный ML-протокол позволяет структурно вести работу над созданием модели, исключая уже на ранних этапах ошибки, и уже в самом начале строить прогзнозы на будущую модель.   
