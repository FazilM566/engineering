# HW07 – Report

## 1. Datasets

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк,9 столбцов)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы,выбросы,шум.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк,4 столбца)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: выбросы,шум,нелинейная структура.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000 строк,33 столбцов)
- Признаки: числовые,категориальные
- Пропуски: да,в числовых (+- 200 в каждом признаке).
- "Подлости" датасета: высокая размерность,категориальные признаки,пропуски.

## 2. Protocol

- Препроцессинг: scaling, imputation, one-hot encoding.
- Поиск гиперпараметров:
  - диапазон параметров: для KMeans (k от 2 до 21), Agglomerative (n_clusters от 2 до 21,linkage: "ward", "complete"),DBSCAN (eps:1.5, 2.0, 2.5, 3.0, 3.5, min_samples: 3, 5, 10)
  - для поиска "лучшего" руководствовался внутреннеми метриками.
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (для DBSCAN при наличии шума метрики равнялись None).
- Визуализация: PCA(2D) и t-SNE(random_state = 42).

## 3. Models

- KMeans (подбирал `k`, фиксировал `random_state` = 42, `n_init` = "auto") для датасетов A,B,C.

- DBSCAN (подбирал `eps`, `min_samples`,учет доли шума) для датасетов A,B,C.

- AgglomerativeClustering (подбирал `k`, `linkage`) для датасета A.

## 4. Results

### 4.1 Dataset A

- Лучший метод DBSCAN(eps': 2.0, 'min_samples': 3).
- Метрики: silhouette,DB,CH.
- Доля шума 0(небольшой датасет с малым колличесвом признаком).
- Учитывает шум, если он есть, и более сложная модель относительно других.

### 4.2 Dataset B

- Лучший метод DBSCAN(eps': 2.0, 'min_samples': 3).
- Метрики: silhouette,DB,CH.
- Доля шума 0(был опредлен лишь 1 кластер).
- Разделяет кластеры по плотности,не уязвим на шумовой признак.

### 4.3 Dataset C

- Лучший метод DBSCAN(eps': 3.0, 'min_samples': 3).
- Метрики: silhouette,DB,CH.
- Доля шума 0.0082(Немного и немало - самый раз для более реального датасета).
- Учет шума.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" при высокой плотности и шумовых признаках, тк задается фиксированное колличество цетройдов.
- DBSCAN выигрывают т.к. учитывает шум и разделяет на кластеры по плотности, сам находит колличесво кластеров.
- Сильнее всего влияло на результат влияли масштабирование и выбросы.

### 5.2 Устойчивость (обязательно для одного датасета)

- 5 запусков KMeans по разным random_state для датасета A.
- Метрики для k = 2:
  Silhouette: 0.5216395622404242
  Davies-Bouldin: 0.6853295219054459
  Calinski-Harabasz: 11786.95462267153
  Метрики для k = 2:
  Silhouette: 0.5216395622404242
  Davies-Bouldin: 0.6853295219054459
  Calinski-Harabasz: 11786.95462267153
  Метрики для k = 2:
  Silhouette: 0.5216395622404242
  Davies-Bouldin: 0.6853295219054459
  Calinski-Harabasz: 11786.95462267153
  Метрики для k = 2:
  Silhouette: 0.5216395622404242
  Davies-Bouldin: 0.6853295219054459
  Calinski-Harabasz: 11786.95462267153
  Метрики для k = 2:
  Silhouette: 0.5216395622404242
  Davies-Bouldin: 0.6853295219054459
  Calinski-Harabasz: 11786.95462267153
- Метрики не поменялись, модель показала абсолютную устйчивость.

### 5.3 Интерпретация кластеров

- Интерпретировал кластеры как профили признаков.
  
- Интерпретация кластеров хороша видна при визуализации. При большом колличестве признаков можно понизить размерность и уже на 2D посмотреть разделенение. Такой подход важен т.к. дает возможно оценить работу и качество модели.

## 6. Conclusion

При кластеризации понял важность предобработки, особенно маштабируемость признаков. Метрики хорошо визуализировать, так сам больше понимаешь как они работают.Построение граммотного паплайна сокращет время и структуирует процесс, делая его качественее.
